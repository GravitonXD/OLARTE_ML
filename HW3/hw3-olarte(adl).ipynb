{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Notebook for HW3\n",
    "This notebook was created to retrain the linear model until we are able to find a model,\n",
    "wherein the r^2 score of the test dataset is better than the train dataset\n",
    "By: John Markton Olarte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NOTE: sklearn should only be used for the following:\n",
    "#     Standardization and Dividing the Data into Training and Testing Sets\n",
    "#     Checking MSE and r^2 values\n",
    "#     Lastly for comparison of implementation (from scratch) and the OLS results since sklearn uses least squares for linear regression.\n",
    "from sklearn import preprocessing                           # Used for standardization\n",
    "from sklearn.model_selection import train_test_split        # Used for dividing the dataset into training and testing sets\n",
    "from sklearn.metrics import r2_score, mean_squared_error    # Used for checking MSE and r^2 values\n",
    "from sklearn.linear_model import LinearRegression           # Used for the OLS results\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from Advertising.csv into a pandas dataframe\n",
    "df = pd.read_csv('Advertising.csv')\n",
    "\n",
    "# Dataframe Cleaning\n",
    "# Since the first column is just the index, we can drop it\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# In this process, we will be using the preprocessing.scale function from sklearn\n",
    "df_standardized = preprocessing.scale(df)\n",
    "\n",
    "# Convert the standardized data into a dataframe\n",
    "df_standardized = pd.DataFrame(df_standardized, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_ones</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.969852</td>\n",
       "      <td>0.981522</td>\n",
       "      <td>1.778945</td>\n",
       "      <td>1.552053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.197376</td>\n",
       "      <td>1.082808</td>\n",
       "      <td>0.669579</td>\n",
       "      <td>-0.696046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.516155</td>\n",
       "      <td>1.528463</td>\n",
       "      <td>1.783549</td>\n",
       "      <td>-0.907406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052050</td>\n",
       "      <td>1.217855</td>\n",
       "      <td>1.286405</td>\n",
       "      <td>0.860330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.394182</td>\n",
       "      <td>-0.841614</td>\n",
       "      <td>1.281802</td>\n",
       "      <td>-0.215683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.270941</td>\n",
       "      <td>-1.321031</td>\n",
       "      <td>-0.771217</td>\n",
       "      <td>-1.234053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.617035</td>\n",
       "      <td>-1.240003</td>\n",
       "      <td>-1.033598</td>\n",
       "      <td>-0.830548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0.349810</td>\n",
       "      <td>-0.942899</td>\n",
       "      <td>-1.111852</td>\n",
       "      <td>-0.234898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>1.594565</td>\n",
       "      <td>1.265121</td>\n",
       "      <td>1.640850</td>\n",
       "      <td>2.205347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993206</td>\n",
       "      <td>-0.990165</td>\n",
       "      <td>-1.005979</td>\n",
       "      <td>-0.119610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     all_ones        TV     Radio  Newspaper     Sales\n",
       "0           1  0.969852  0.981522   1.778945  1.552053\n",
       "1           1 -1.197376  1.082808   0.669579 -0.696046\n",
       "2           1 -1.516155  1.528463   1.783549 -0.907406\n",
       "3           1  0.052050  1.217855   1.286405  0.860330\n",
       "4           1  0.394182 -0.841614   1.281802 -0.215683\n",
       "..        ...       ...       ...        ...       ...\n",
       "195         1 -1.270941 -1.321031  -0.771217 -1.234053\n",
       "196         1 -0.617035 -1.240003  -1.033598 -0.830548\n",
       "197         1  0.349810 -0.942899  -1.111852 -0.234898\n",
       "198         1  1.594565  1.265121   1.640850  2.205347\n",
       "199         1  0.993206 -0.990165  -1.005979 -0.119610\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to add this column as it will serve as our bias term.\n",
    "# Basically, in the formula y = theta_0 + theta_1 * x_1 + theta_2 * x_2 + ... + theta_n * x_n\n",
    "#   The theta_0 is the bias term and for us to include it in the computation we need to add a column of 1's.\n",
    "#   theta_0 * 1 = theta_0 (by Identity Property of Multiplication)\n",
    "df_standardized.insert(0, 'all_ones', 1)\n",
    "df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: TV, Radio, Newspaper, and all_ones (bias term)\n",
    "features = df_standardized[['all_ones', 'TV', 'Radio', 'Newspaper']]\n",
    "# Select the Sales column as the target (response) variable\n",
    "response = df_standardized['Sales']\n",
    "\n",
    "# We will be using 75% of the data for training and 25% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, response, train_size=0.75, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(X, random=False):\n",
    "    # Initialize the length of the weights to the number of columns in X\n",
    "    len_X = X.shape[1]\n",
    "    \n",
    "    # If the random parameter is set to True, then we will initialize the weights randomly\n",
    "    if random:\n",
    "        return np.random.rand(len_X)\n",
    "    # Otherwise, by default, we will initialize the weights to zero\n",
    "    return np.zeros(len_X)\n",
    "\n",
    "def predict(X, weights):\n",
    "    # From the formula we need to multiply each weight to its corresponding feature from X\n",
    "    #   we can do this using the dot product function from numpy.\n",
    "    y_hat = np.dot(X, weights)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "def compute_cost(X, y, weights):  \n",
    "    # Initialize the length of the data\n",
    "    # The length of the data is equal to the length of either the response or the features\n",
    "    # For simplicity, we will use the length of the response\n",
    "    m = len(y)\n",
    "\n",
    "    # Calculate the cost function\n",
    "    # From the formula, we need to square the difference between the predicted and actual values and find their sum\n",
    "    #   as indicated by this formula [sum((y_hat - y)^2)]\n",
    "    #   and then we need to multiply it by 1/2m.\n",
    "    cost = 1/(2*m) * np.sum((predict(X, weights) - y)**2)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def compute_gradient(X, y, weights):\n",
    "    # Initialize the length of the data\n",
    "    m = len(y)\n",
    "    \n",
    "    # X.T is the transpose of X which we will apply to each difference between the predicted and actual values using the dot product.\n",
    "    w = 1/m * np.dot(X.T, (predict(X, weights) - y))\n",
    "\n",
    "    return w\n",
    "\n",
    "def update_weights(X, y, weights, alpha):\n",
    "    # Update the weights: theta = theta - alpha * gradient\n",
    "    #   As mentioned from my notes in compute_gradient, we need to multiply alpha (learning rate) to the gradient\n",
    "    #   and then subtract it from the weights.\n",
    "    updated_weights = weights - alpha * compute_gradient(X, y, weights)\n",
    "\n",
    "    return updated_weights\n",
    "\n",
    "def gradient_descent(X, y, weights, alpha, iterations):\n",
    "    # Since we are to produce 2 matrices, we first initialize these two matrices\n",
    "    weights_history = [0] * iterations\n",
    "    cost_history = [0] * iterations\n",
    "\n",
    "    # Loop through the number of iterations\n",
    "    # NOTE: There are actually two main types of gradient descent, batch gradient descent and stochastic gradient descent.\n",
    "    #      In our case, we are implementing the batch gradient descent. That is why we are looping through the entire dataset.\n",
    "    #      If we were to implement the stochastic gradient descent, we would only need to loop through a single data point.\n",
    "    for i in range(iterations):\n",
    "        # Update the weights\n",
    "        weights = update_weights(X, y, weights, alpha)\n",
    "        # Save the weights in the weights history matrix\n",
    "        weights_history[i] = weights\n",
    "        # Compute the cost\n",
    "        cost = compute_cost(X, y, weights)\n",
    "        # Save the cost in the cost history matrix\n",
    "        cost_history[i] = cost\n",
    "    \n",
    "    return weights_history, cost_history\n",
    "\n",
    "def plot_costs(cost_array):\n",
    "    # Set the size of the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(cost_array)\n",
    "    plt.title('Cost over Iterations')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Weights: [0.79230802 0.79409756 0.22644812 0.92839463]\n",
      "Optimal Weights: [ 0.00487484  0.75809584  0.52960603 -0.02070791]\n",
      "Iteration 1 - r^2 score train: 0.8899415563505054, r^2 score test: 0.9157629399026007\n",
      "\n",
      "----FINAL----\n",
      "Optimal Weights: [ 0.00487484  0.75809584  0.52960603 -0.02070791]\n",
      "r^2 score train: 0.8899415563505054\n",
      "r^2 score test: 0.9157629399026007\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal weights using the training set (Do this until r^2 score train < test)\n",
    "r2_score_train = 0\n",
    "r2_score_test = 0\n",
    "optimal_weights = []\n",
    "iteration = 1\n",
    "\n",
    "while (r2_score_train >= r2_score_test):\n",
    "    init_w = initialize_weights(X_train, random=True) # We will use random initialization\n",
    "    print(f\"Inital Weights: {init_w}\")\n",
    "\n",
    "    # Set the iterations and the learning rate\n",
    "    iterations = 50000                          # Let's do 50,000 iterations, as recommended in the activity guide.\n",
    "    alpha = 0.01                                 # Let's use a learning rate of 0.01\n",
    "\n",
    "    # Run the gradient descent algorithm\n",
    "    weights_history, cost_history = gradient_descent(X_train, y_train, init_w, alpha, iterations)\n",
    "\n",
    "    # Get the final weights (Optimal weights)\n",
    "    # We will assume that the optimal weights are the weights that give us the lowest cost, \n",
    "    #   which can be found at the end of the weights_history array.\n",
    "    optimal_weights = weights_history[-1]\n",
    "    print(f\"Optimal Weights: {optimal_weights}\")\n",
    "\n",
    "    # calculate r^2 scores\n",
    "    r2_score_train = r2_score(y_train, predict(X_train, optimal_weights))\n",
    "    r2_score_test = r2_score(y_test, predict(X_test, optimal_weights))\n",
    "\n",
    "    print(f\"Iteration {iteration} - r^2 score train: {r2_score_train}, r^2 score test: {r2_score_test}\\n\")\n",
    "    iteration += 1\n",
    "    \n",
    "\n",
    "print(\"----FINAL----\")\n",
    "# Print the optimal weights\n",
    "print(f\"Optimal Weights: {optimal_weights}\")\n",
    "\n",
    "# Print the r^2 scores\n",
    "print(f\"r^2 score train: {r2_score_train}\")\n",
    "print(f\"r^2 score test: {r2_score_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1224d32f05aa8d9d17993b21a51be44b2d1966ef541559ad6beae9001f15c664"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
