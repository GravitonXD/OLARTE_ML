{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING OF TREC 06 DATA\n",
    "by: John Markton Olarte\n",
    "This is done in a seperate notebook to avoid having to re-run the preprocesing in the main notebook (hw6-olarte.ipynb).\n",
    "\n",
    "The emails will be preprocessed in this notebook, and as an output we will have the following csv files:\n",
    "a. train_ham.csv - contains the preprocessed ham emails from the training set (folders 0 to 70)\n",
    "b. train_spam.csv - contains the preprocessed spam emails from the training set (folders 0 to 70)\n",
    "d. test_set.csv - contains the preprocessed emails from the test set (both ham and spam, folders: 71 to 126)\n",
    "d. preprocessed_emails.csv - contains the preprocessed emails from the training and test sets (both ham and spam, folders: 0 to 126)\n",
    "This CSV files will then be used in the main notebook (hw6-olarte.ipynb) to train the model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import os # This will be used to access the files in the trec06 directory\n",
    "import re # This will be used to remove the html tags from the emails\n",
    "# NOTE: Removal of html tags in the email data was not mentioned in the problem set guide, but I decided\n",
    "#   to add this, as upon manual inspection of the data, I noticed that there were html tags in the data,\n",
    "#   which can affect the accuracy of the model if not removed.\n",
    "import email # This will be used to parse the emails\n",
    "import pandas as pd # This will be used to create the dataframe and exporting of files to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Main Dataframe and Labels Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DATAFRAME\n",
    "\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "# COLUMNS: folder, file, email_message, category\n",
    "#   folder: folder where the email is located\n",
    "#   file: file name of the email\n",
    "#   email_message: email message\n",
    "#   category: 0-ham, 1-spam\n",
    "df_main # This should be empty at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS DATAFRAME\n",
    "# NOTE: This is a temporary dataframe that will be used to store the labels of the emails based on the labels file\n",
    "path_to_labels = \"trec06/labels\"\n",
    "\n",
    "# Upon inspection of the labels file, I noticed that the labels are in the format of \"category file_path\"\n",
    "#    we will use this in our advantage as we can use the file_path:../data/{folder}/{file} to label the emails later in the main dataframe\n",
    "df_labels = pd.read_csv(\"trec06/labels\", sep=\" \", header=None)\n",
    "# Assign the column names\n",
    "df_labels.columns = [\"category\", \"file_path\"]\n",
    "# Change category from ham/spam to 0/1\n",
    "df_labels[\"category\"] = df_labels[\"category\"].apply(lambda x: 0 if x == \"ham\" else 1)\n",
    "# Remove \"../data/\" from file_path\n",
    "df_labels[\"file_path\"] = df_labels[\"file_path\"].apply(lambda x: x.replace(\"../data/\", \"\"))\n",
    "\n",
    "# Show the labels dataframe\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS FOR REMOVING USELESS INFORMATION, AND GETTING MESSAGE BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the path to the data directory and list the folders in the data directory\n",
    "folder_path = \"trec06/data\"\n",
    "folders = os.listdir(folder_path)\n",
    "folders # This is to show the folders in the data directory\n",
    "# NOTE: We can see that there is no folder:127 which was indicated end of range for test data in the problem set guide\n",
    "#    However upon checking on the zipped file README, we can see that the test data is from 71-126 only, so we will use this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of useless information to be removed from the email\n",
    "stop_words = []\n",
    "punctuations = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\\\\\"\n",
    "numbers = \"0123456789\"\n",
    "html_tags = re.compile('<.*?>') # This will be used to remove html tags from the email, remember html tags are enclosed in <>\n",
    "\n",
    "# Use stop_words file to get the stop words\n",
    "with open(\"stop_words.txt\", \"r\") as f:\n",
    "    stop_word = f.read().splitlines()\n",
    "    stop_words = [word for word in stop_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove useless pieces of information from the email\n",
    "def remove_useless_info(message):\n",
    "    # Convert to lower case, since stop words are in lower case\n",
    "    message = message.lower()\n",
    "    # remove html tags\n",
    "    message = re.sub(html_tags, '', message)\n",
    "    # Remove symbols\n",
    "    message = message.translate(str.maketrans('', '', punctuations))\n",
    "    # Remove numbers\n",
    "    message = message.translate(str.maketrans('', '', numbers))\n",
    "    # split message into words\n",
    "    words = message.split()\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Rejoin words into a message\n",
    "    message = \" \".join(words)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect messagge from parsed email\n",
    "def get_message(parsed_email):\n",
    "    message = \"\"\n",
    "    # Check if the email is multipart\n",
    "    if parsed_email.is_multipart():\n",
    "        # Loop through the parts of the email\n",
    "        for part in parsed_email.walk():\n",
    "            # Check if the part is text/plain\n",
    "            if part.get_content_type() == \"text/plain\":\n",
    "                # Get the message\n",
    "                message = part.get_payload()\n",
    "                break\n",
    "    # If the email is not multipart, just get the message\n",
    "    else:\n",
    "        message = parsed_email.get_payload()\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we loop through all 30,000 emails. Let us first try our functions on a single email to see it it works properly\n",
    "test_folder = \"012\"\n",
    "test_file = \"103\"\n",
    "test_path = f\"trec06/data/{test_folder}/{test_file}\"\n",
    "charset = \"\"\n",
    "with open(test_path, \"r\") as f:\n",
    "    # Get the charset of the email\n",
    "    charset = email.message_from_file(f).get_content_charset()\n",
    "charset = charset if charset else \"windows-1251\" # If charset is None, set it to utf-8\n",
    "\n",
    "# We will use encoding=\"ISO-8859-1\" since emails are usually encoded in this format\n",
    "with open(test_path, 'r', encoding=charset) as e_mail:\n",
    "    read_email = e_mail.read()\n",
    "    parsed_email = email.message_from_string(read_email)\n",
    "\n",
    "    # Original email message\n",
    "    message = get_message(parsed_email)\n",
    "    print(f\"original message: {message}\")\n",
    "\n",
    "    # Processed email message\n",
    "    message = remove_useless_info(message)\n",
    "    print(f\"processed message: {message}\")\n",
    "e_mail.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that it is working, we can now apply it to the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING OF THE WHOLE TREC06 DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are different ways I wanted to preprocess the data:\n",
    "<ol>\n",
    "<li> [a] I'll just preprocess each email in a standard charset (ISO-8859-1), and then remove any useless information. Also all data will be preserved regardless of how they are encoded. </li>\n",
    "<li> [b] I'll process each email with their corresponding charset, and then remove any useless information. </li>\n",
    "<li> [c] A variation of (a), wherein blanked messages will be removed. </li>\n",
    "<li> [d] A variation of (b), wherein blanked messages will be removed. </li>\n",
    "<li> [e] variation of (c), wherein all non-ascii chars are also removed. </li>\n",
    "</ol>\n",
    "There are a lot more variations, but for the sake of time we'll just do these 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing type (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing type [a]\n",
    "\n",
    "# Read all emails and put them in a dataframe\n",
    "for folder in folders:\n",
    "    # Get the files in the folder\n",
    "    files = os.listdir(f\"{folder_path}/{folder}\")\n",
    "    for file in files:\n",
    "        with open(f\"{folder_path}/{folder}/{file}\", \"r\", encoding=\"ISO-8859-1\") as e_mail:\n",
    "            # Read email file\n",
    "            read_email = e_mail.read()\n",
    "            # Parse email\n",
    "            parsed_email = email.message_from_string(read_email)\n",
    "            # Get message\n",
    "            message = get_message(parsed_email)\n",
    "            # Remove useless information\n",
    "            message = remove_useless_info(message)\n",
    "            # Get the category of the email based on the labels df\n",
    "            category_label = df_labels[df_labels[\"file_path\"] == f\"{folder}/{file}\"][\"category\"].values[0]\n",
    "            # Concatenate the data to the df_main\n",
    "            df_main = pd.concat([df_main, pd.DataFrame([[folder, file, message, category_label]], columns=[\"folder\", \"file\", \"email_message\", \"category\"])], ignore_index=True)\n",
    "# Show the main dataframe\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed_files folder exists\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(\"preprocessed_files\"):\n",
    "    os.makedirs(\"preprocessed_files\")\n",
    "\n",
    "# Save df_main as preprocessed_emails_a.csv\n",
    "df_main.to_csv(\"preprocessed_files/preprocessed_emails_a.csv\", index=False)\n",
    "\n",
    "# Reset the main dataframe, to not overload the memory\n",
    "df_main.drop(df_main.index, inplace=True)\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "df_main # This should be an empty dataframe again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing type (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing type [b]\n",
    "\n",
    "# Read all emails and put them in a dataframe\n",
    "for folder in folders:\n",
    "    # Get all files in folder\n",
    "    files = os.listdir(f\"{folder_path}/{folder}\")\n",
    "    for file in files:\n",
    "        # Determine the charset of the email\n",
    "        charset = \"\"\n",
    "        try:\n",
    "            with open(f\"{folder_path}/{folder}/{file}\", \"r\") as f:\n",
    "                # Get the charset of the email\n",
    "                charset = email.message_from_file(f).get_content_charset()\n",
    "        except:\n",
    "            charset = None\n",
    "        charset = charset if charset else \"windows-1251\" # If charset is None, set it to utf-8\n",
    "\n",
    "        try:\n",
    "            with open(f\"{folder_path}/{folder}/{file}\", \"r\", encoding=charset) as e_mail:\n",
    "                # Read email file\n",
    "                read_email = e_mail.read()\n",
    "                # Parse email\n",
    "                parsed_email = email.message_from_string(read_email)\n",
    "                # Get message\n",
    "                message = get_message(parsed_email)\n",
    "                # Remove useless information\n",
    "                message = remove_useless_info(message)\n",
    "                # Get the category of the email based on the labels df\n",
    "                category_label = df_labels[df_labels[\"file_path\"] == f\"{folder}/{file}\"][\"category\"].values[0]\n",
    "                # Concatenate the data to the df_main\n",
    "                df_main = pd.concat([df_main, pd.DataFrame([[folder, file, message, category_label]], columns=[\"folder\", \"file\", \"email_message\", \"category\"])], ignore_index=True)\n",
    "        except:\n",
    "            # Open the file in binary mode\n",
    "            with open(f\"{folder_path}/{folder}/{file}\", \"rb\") as e_mail:\n",
    "                # Read email file\n",
    "                read_email = e_mail.read()\n",
    "                # Parse email\n",
    "                parsed_email = email.message_from_bytes(read_email)\n",
    "                # Get message\n",
    "                message = get_message(parsed_email)\n",
    "                # Remove useless information\n",
    "                message = remove_useless_info(message)\n",
    "                # Get the category of the email based on the labels df\n",
    "                category_label = df_labels[df_labels[\"file_path\"] == f\"{folder}/{file}\"][\"category\"].values[0]\n",
    "                # Concatenate the data to the df_main\n",
    "                df_main = pd.concat([df_main, pd.DataFrame([[folder, file, message, category_label]], columns=[\"folder\", \"file\", \"email_message\", \"category\"])], ignore_index=True)\n",
    "\n",
    "# Show the main dataframe\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed_files folder exists\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(\"preprocessed_files\"):\n",
    "    os.makedirs(\"preprocessed_files\")\n",
    "\n",
    "# Save df_main as preprocessed_emails_b.csv\n",
    "df_main.to_csv(\"preprocessed_files/preprocessed_emails_b.csv\", index=False)\n",
    "\n",
    "# Reset the main dataframe, to not overload the memory\n",
    "df_main.drop()\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "df_main # This should be an empty dataframe again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing type (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing type [c]\n",
    "\n",
    "# Since this is a variation of preprocessing type [a], we can use the exported csv file from preprocessing type [a]\n",
    "df_main = pd.read_csv(\"preprocessed_files/preprocessed_emails_a.csv\")\n",
    "\n",
    "# Remove all messages that are empty\n",
    "df_main = df_main[df_main[\"email_message\"] != \"\"]\n",
    "\n",
    "# Show the main dataframe\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed_files folder exists\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(\"preprocessed_files\"):\n",
    "    os.makedirs(\"preprocessed_files\")\n",
    "\n",
    "# Save df_main as preprocessed_emails_c.csv\n",
    "df_main.to_csv(\"preprocessed_files/preprocessed_emails_c.csv\", index=False)\n",
    "\n",
    "# Reset the main dataframe, to not overload the memory\n",
    "df_main.drop()\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "df_main # This should be an empty dataframe again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing type (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing type [d]\n",
    "\n",
    "# Since this is a variation of preprocessing type [b], we can use the exported csv file from preprocessing type [b]\n",
    "df_main = pd.read_csv(\"preprocessed_files/preprocessed_emails_b.csv\")\n",
    "\n",
    "# Remove all messages that are empty\n",
    "df_main = df_main[df_main[\"email_message\"] != \"\"]\n",
    "\n",
    "# Show the main dataframe\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed_files folder exists\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(\"preprocessed_files\"):\n",
    "    os.makedirs(\"preprocessed_files\")\n",
    "\n",
    "# Save df_main as preprocessed_emails_d.csv\n",
    "df_main.to_csv(\"preprocessed_files/preprocessed_emails_d.csv\", index=False)\n",
    "\n",
    "# Reset the main dataframe, to not overload the memory\n",
    "df_main.drop()\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "df_main # This should be an empty dataframe again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing type (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing type [e]\n",
    "\n",
    "# Since this is a variation of preprocessing type [c], we can use the exported csv file from preprocessing type [c]\n",
    "df_main = pd.read_csv(\"preprocessed_files/preprocessed_emails_b.csv\")\n",
    "\n",
    "# Process messages and remove characters that are not ascii\n",
    "df_main[\"email_message\"] = df_main[\"email_message\"].apply(lambda x: x.encode(\"ascii\", \"ignore\").decode())\n",
    "\n",
    "# Show the main dataframe\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed_files folder exists\n",
    "# Create the folder if it does not exist\n",
    "if not os.path.exists(\"preprocessed_files\"):\n",
    "    os.makedirs(\"preprocessed_files\")\n",
    "\n",
    "# Save df_main as preprocessed_emails_e.csv\n",
    "df_main.to_csv(\"preprocessed_files/preprocessed_emails_e.csv\", index=False)\n",
    "\n",
    "# Reset the main dataframe, to not overload the memory\n",
    "df_main.drop()\n",
    "df_main = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "df_main # This should be an empty dataframe again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bce94cf5ba4e91c139e25acaf699abf418036a78723bf02e000e119123230ea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
